{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting: wragle_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To wrangle WeRateDogs Twitter data to create interesting and trustworthy analyses and visualizations, three seperate files was gathered which are Enhanced Twitter Archive data, Image Predictions File and Tweet file in json form.\n",
    "Since real-world data are frequently unclean, the following actions are being taken to make some of this data clean so that it is suitable for analysis.\n",
    "1. The following are the wrangling efforts made after reading in the twitter-archive-enhanced file and saving it into a dataframe with the name dog rate:\n",
    "- To display the first few rows of the dog_rate dataframe, the .head() method was utilized.\n",
    "- The dog_rate dataframe's information was shown using the .info() method.\n",
    "- To display the count of the distinct values in the rating_numerator, rating_denominator, and name column, the .value_counts() method was utilized.\n",
    "- .duplicated().sum() method was used to determine how many duplicates there were in the dog_rate dataframe.\n",
    "\n",
    "    In all the above wrangling effort on the twitter-archive-enhanced dataframe, the quality issues found out are:\n",
    "- incorrect datatype in the timestamp column.\n",
    "- No need for the replies and retweet rows.\n",
    "- No need for the replies and retweet columns.\n",
    "- In rating_denominator, some values are less than 10.\n",
    "\n",
    "2. The following are the wrangling efforts done after downloading the tweet image prediction file using the request library and reading it into a dataframe with the name image_predictions:\n",
    "- To display the first few rows of the image_predictions dataframe, the .head() method was utilized.\n",
    "- The image_predictions dataframe's information was shown using the .info() method.\n",
    "- .duplicated().sum() method was used to determine how many duplicates there were in the image_predictions dataframe.\n",
    "\n",
    "    In all the above wrangling effort on the tweets_df dataframe, the quality issues found out are:\n",
    "- The names in the P columns have some lowercase and some uppercase initials.\n",
    "- The conf should be written completely to facilitate understanding.\n",
    "\n",
    "3. The tweet json.txt was handled almost in the same way that the first data and second file were handled.\n",
    "- created a dataframe from the tweet list of dictionaries using the pd.DataFrame() function, saving it as a dataframe with the name tweets_df.\n",
    "\n",
    "    In all the wrangling effort on the tweets_df dataframe, the quality issues found out are:\n",
    "- To match the other tables, the id field should be \"tweet id.\"\n",
    "- No need for the retweet_count column.\n",
    "\n",
    "The tidiness difficulties that result from the aforementioned wrangling effort are:\n",
    "- There should be just one column for doggo, floofer, pupper, and puppo in the dog_rate dataframe.\n",
    "- Create a single dataframe from the three gathered data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
